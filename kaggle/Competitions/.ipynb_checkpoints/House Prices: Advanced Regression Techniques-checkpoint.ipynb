{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# creating file handler for \\n# our example.csv file in\\n# read mode\\nfile_handler = open(\"/home/ash/Downloads/all/test.csv\", \"r\")\\n \\n# creating a Pandas DataFrame\\n# using read_csv function \\n# that reads from a csv file.\\ndata = pd.read_csv(file_handler, sep = \",\")\\n \\n# closing the file handler\\nfile_handler.close()\\n \\n# creating a dict file \\nstreet = {0:0,\\'Grvl\\': 1,\\'Pave\\': 2}\\nzone = {0:0,\\'A\\': 1,\\'C (all)\\': 2,\\'FV\\':3,\\'I\\':4,\\'RH\\':5,\\'RL\\':6,\\'RP\\':7,\\'RM\\':8}\\nalley = {0:0,\\'Grvl\\':1,\\'Pave\\':2,\\'NA\\':0}\\nlot = {0:0,\\'Reg\\':1,\\'IR1\\':2,\\'IR2\\':3,\\'IR3\\':4}\\ncontour = {0:0,\\'Lvl\\':1,\\'Bnk\\':2,\\'HLS\\':3,\\'Low\\':4}\\nutils = {0:0,\\'AllPub\\':1,\\'Nosewr\\':2,\\'NoSeWa\\':3,\\'ELO\\':4}\\nlotconfig = {0:0,\\'Inside\\':1,\\'Corner\\':2,\\'CulDSac\\':3,\\'FR2\\':4,\\'FR3\\':5}\\nlandslop = {0:0,\\'Gtl\\':1,\\'Mod\\':2,\\'Sev\\':3}\\nnhd = {0:0,\\'Blmngtn\\':1,\\'Blueste\\':2,\\'BrDale\\':3,\\'BrkSide\\':4,\\'ClearCr\\':5,\\'CollgCr\\':6,\\'Crawfor\\':7,\\'Edwards\\':8,\\'Gilbert\\':9,\\'IDOTRR\\':10,\\'MeadowV\\':11,\\'Mitchel\\':12,\\'NAmes\\':13,\\'NoRidge\\':14,\\'NPkVill\\':15,\\'NridgHt\\':16,\\'NWAmes\\':17,\\'OldTown\\':18,\\'SWISU\\':19,\\'Sawyer\\':20,\\'SawyerW\\':21,\\'Somerst\\':22,\\'StoneBr\\':23,\\'Timber\\':24,\\'Veenker\\':25}\\ncond = {0:0,\\'Artery\\':1,\\'Feedr\\':2,\\'Norm\\':3,\\'RRNn\\':4,\\'RRAn\\':5,\\'PosN\\':6,\\'PosA\\':7,\\'RRNe\\':8,\\'RRAe\\':9}\\nbtype = {0:0,\\'1Fam\\':1,\\'2fmCon\\':2,\\'Duplex\\':3,\\'TwnhsE\\':4,\\'TwnhsI\\':5,\\'Twnhs\\':6}\\nhstyle = {0:0,\\'1Story\\':1,\\'1.5Fin\\':2,\\'1.5Unf\\':3,\\'2Story\\':4,\\'2.5Fin\\':5,\\'2.5Unf\\':6,\\'SFoyer\\':7,\\'SLvl\\':8}\\nroof = {0:0,\\'Flat\\':1,\\'Gable\\':2,\\'Gambrel\\':3,\\'Hip\\':4,\\'Mansard\\':5,\\'Shed\\':6}\\nroofmatl = {0:0,\\'ClyTile\\':1,\\'CompShg\\':2,\\'Membran\\':3,\\'Metal\\':4,\\'Roll\\':5,\\'Tar&Grv\\':6,\\'WdShake\\':7,\\'WdShngl\\':8}\\next = {0:0,\\'AsbShng\\':1,\\'AsphShn\\':2,\\'BrkComm\\':3,\\'Brk Cmn\\':3,\\'BrkFace\\':4,\\'CBlock\\':5,\\'CemntBd\\':6,\\'CmentBd\\':6,\\'HdBoard\\':7,\\'ImStucc\\':8,\\'MetalSd\\':9,\\'Other\\':10,\\'Plywood\\':11,\\'PreCast\\':12,\\'Stone\\':13,\\'Stucco\\':14,\\'VinylSd\\':15,\\'Wd Shng\\':16,\\'Wd Sdng\\':16,\\'WdShing\\':17}\\nmvt = {0:0,\\'BrkCmn\\':1,\\'BrkFace\\':2,\\'CBlock\\':3,\\'None\\':4,\\'Stone\\':5}\\neq = {0:0,\\'Ex\\':1,\\'Gd\\':2,\\'TA\\':3,\\'Fa\\':4,\\'Po\\':5}\\nfound = {0:0,\\'BrkTil\\':1,\\'CBlock\\':2,\\'PConc\\':3,\\'Slab\\':4,\\'Stone\\':5,\\'Wood\\':6}\\nbsmt_type = {0:0,\\'GLQ\\':1,\\'ALQ\\':2,\\'BLQ\\':3,\\'Rec\\':4,\\'LwQ\\':5,\\'Unf\\':6}\\nbex = {0:0,\\'Gd\\':1,\\'Av\\':2,\\'Mn\\':3,\\'No\\':4}\\nheat = {0:0,\\'Floor\\':1,\\'GasA\\':2,\\'GasW\\':3,\\'Grav\\':4,\\'OthW\\':5,\\'Wall\\':6}\\nyesno = {0:0, \\'N\\':1,\\'Y\\':2}\\nelect = {0:0,\\'SBrkr\\':1,\\'FuseA\\':2,\\'FuseF\\':3,\\'FuseP\\':4,\\'Mix\\':5}\\nfunc = {0:0,\\'Typ\\':1,\\'Min1\\':2,\\'Min2\\':3,\\'Mod\\':4,\\'Maj1\\':5,\\'Maj2\\':6,\\'Sev\\':7,\\'Sal\\':8}\\ngt = {0:0,\\'2Types\\':1,\\'Attchd\\':2,\\'Basment\\':3,\\'BuiltIn\\':4,\\'CarPort\\':5,\\'Detchd\\':6}\\ngfin = {0:0,\\'Fin\\':1,\\'RFn\\':2,\\'Unf\\':3}\\npd = {0:0,\\'Y\\':1,\\'P\\':2,\\'N\\':3}\\nfence = {0:0,\\'GdPrv\\':1,\\'MnPrv\\':2,\\'GdWo\\':3,\\'MnWw\\':4}\\nmisc = {0:0,\\'Elev\\':1,\\'Gar2\\':2,\\'Othr\\':3,\\'Shed\\':4,\\'TenC\\':5}\\nstype = {0:0,\\'WD\\':1,\\'CWD\\':2,\\'VWD\\':3,\\'New\\':4,\\'COD\\':4,\\'Con\\':5,\\'ConLw\\':6,\\'ConLI\\':7,\\'ConLD\\':8,\\'Oth\\':9}\\nscond = {0:0,\\'Normal\\':1,\\'Abnorml\\':2,\\'AdjLand\\':3,\\'Alloca\\':4,\\'Family\\':5,\\'Partial\\':6}\\n# traversing through dataframe\\n# Gender column and writing\\n# values where key matches\\ndata=data.fillna(0)\\ndata.MSZoning = [zone[item] for item in data.MSZoning]\\ndata.Alley = [alley[item] for item in data.Alley]\\ndata.LotShape = [lot[item] for item in data.LotShape]\\ndata.LandContour = [contour[item] for item in data.LandContour]\\ndata.Utilities = [utils[item] for item in data.Utilities]\\ndata.LotConfig = [lotconfig[item] for item in data.LotConfig]\\ndata.LandSlope = [landslop[item] for item in data.LandSlope]\\ndata.Neighborhood = [nhd[item] for item in data.Neighborhood]\\ndata.Condition1 = [cond[item] for item in data.Condition1]\\ndata.Condition2 = [cond[item] for item in data.Condition2]\\ndata.BldgType = [btype[item] for item in data.BldgType]\\ndata.HouseStyle = [hstyle[item] for item in data.HouseStyle]\\ndata.RoofStyle = [roof[item] for item in data.RoofStyle]\\ndata.RoofMatl = [roofmatl[item] for item in data.RoofMatl]\\ndata.Street = [street[item] for item in data.Street]\\ndata.Exterior1st = [ext[item] for item in data.Exterior1st]\\ndata.Exterior2nd = [ext[item] for item in data.Exterior2nd]\\ndata.MasVnrType = [mvt[item] for item in data.MasVnrType]\\ndata.ExterQual = [eq[item] for item in data.ExterQual]\\ndata.ExterCond = [eq[item] for item in data.ExterCond]\\ndata.Foundation = [found[item] for item in data.Foundation]\\ndata.BsmtQual = [eq[item] for item in data.BsmtQual]\\ndata.BsmtCond = [eq[item] for item in data.BsmtCond]\\ndata.BsmtExposure = [bex[item] for item in data.BsmtExposure]\\ndata.BsmtFinType1 = [bsmt_type[item] for item in data.BsmtFinType1]\\ndata.BsmtFinType2 = [bsmt_type[item] for item in data.BsmtFinType2]\\ndata.Heating = [heat[item] for item in data.Heating]\\ndata.HeatingQC = [eq[item] for item in data.HeatingQC]\\ndata.CentralAir = [yesno[item] for item in data.CentralAir]\\ndata.Electrical = [elect[item] for item in data.Electrical]\\ndata.KitchenQual = [eq[item] for item in data.KitchenQual]\\ndata.Functional = [func[item] for item in data.Functional]\\ndata.FireplaceQu = [eq[item] for item in data.FireplaceQu]\\ndata.GarageType = [gt[item] for item in data.GarageType]\\ndata.GarageFinish = [gfin[item] for item in data.GarageFinish]\\ndata.GarageQual = [eq[item] for item in data.GarageQual]\\ndata.GarageCond = [eq[item] for item in data.GarageCond]\\ndata.PavedDrive = [pd[item] for item in data.PavedDrive]\\ndata.PoolQC = [eq[item] for item in data.PoolQC]\\ndata.Fence = [fence[item] for item in data.Fence]\\ndata.MiscFeature = [misc[item] for item in data.MiscFeature]\\ndata.SaleType = [stype[item] for item in data.SaleType]\\ndata.SaleCondition = [scond[item] for item in data.SaleCondition]\\n\\ndata.to_csv(\\'clean2.csv\\', index=False)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# creating file handler for \n",
    "# our example.csv file in\n",
    "# read mode\n",
    "file_handler = open(\"/home/ash/Downloads/all/test.csv\", \"r\")\n",
    " \n",
    "# creating a Pandas DataFrame\n",
    "# using read_csv function \n",
    "# that reads from a csv file.\n",
    "data = pd.read_csv(file_handler, sep = \",\")\n",
    " \n",
    "# closing the file handler\n",
    "file_handler.close()\n",
    " \n",
    "# creating a dict file \n",
    "street = {0:0,'Grvl': 1,'Pave': 2}\n",
    "zone = {0:0,'A': 1,'C (all)': 2,'FV':3,'I':4,'RH':5,'RL':6,'RP':7,'RM':8}\n",
    "alley = {0:0,'Grvl':1,'Pave':2,'NA':0}\n",
    "lot = {0:0,'Reg':1,'IR1':2,'IR2':3,'IR3':4}\n",
    "contour = {0:0,'Lvl':1,'Bnk':2,'HLS':3,'Low':4}\n",
    "utils = {0:0,'AllPub':1,'Nosewr':2,'NoSeWa':3,'ELO':4}\n",
    "lotconfig = {0:0,'Inside':1,'Corner':2,'CulDSac':3,'FR2':4,'FR3':5}\n",
    "landslop = {0:0,'Gtl':1,'Mod':2,'Sev':3}\n",
    "nhd = {0:0,'Blmngtn':1,'Blueste':2,'BrDale':3,'BrkSide':4,'ClearCr':5,'CollgCr':6,'Crawfor':7,'Edwards':8,'Gilbert':9,'IDOTRR':10,'MeadowV':11,'Mitchel':12,'NAmes':13,'NoRidge':14,'NPkVill':15,'NridgHt':16,'NWAmes':17,'OldTown':18,'SWISU':19,'Sawyer':20,'SawyerW':21,'Somerst':22,'StoneBr':23,'Timber':24,'Veenker':25}\n",
    "cond = {0:0,'Artery':1,'Feedr':2,'Norm':3,'RRNn':4,'RRAn':5,'PosN':6,'PosA':7,'RRNe':8,'RRAe':9}\n",
    "btype = {0:0,'1Fam':1,'2fmCon':2,'Duplex':3,'TwnhsE':4,'TwnhsI':5,'Twnhs':6}\n",
    "hstyle = {0:0,'1Story':1,'1.5Fin':2,'1.5Unf':3,'2Story':4,'2.5Fin':5,'2.5Unf':6,'SFoyer':7,'SLvl':8}\n",
    "roof = {0:0,'Flat':1,'Gable':2,'Gambrel':3,'Hip':4,'Mansard':5,'Shed':6}\n",
    "roofmatl = {0:0,'ClyTile':1,'CompShg':2,'Membran':3,'Metal':4,'Roll':5,'Tar&Grv':6,'WdShake':7,'WdShngl':8}\n",
    "ext = {0:0,'AsbShng':1,'AsphShn':2,'BrkComm':3,'Brk Cmn':3,'BrkFace':4,'CBlock':5,'CemntBd':6,'CmentBd':6,'HdBoard':7,'ImStucc':8,'MetalSd':9,'Other':10,'Plywood':11,'PreCast':12,'Stone':13,'Stucco':14,'VinylSd':15,'Wd Shng':16,'Wd Sdng':16,'WdShing':17}\n",
    "mvt = {0:0,'BrkCmn':1,'BrkFace':2,'CBlock':3,'None':4,'Stone':5}\n",
    "eq = {0:0,'Ex':1,'Gd':2,'TA':3,'Fa':4,'Po':5}\n",
    "found = {0:0,'BrkTil':1,'CBlock':2,'PConc':3,'Slab':4,'Stone':5,'Wood':6}\n",
    "bsmt_type = {0:0,'GLQ':1,'ALQ':2,'BLQ':3,'Rec':4,'LwQ':5,'Unf':6}\n",
    "bex = {0:0,'Gd':1,'Av':2,'Mn':3,'No':4}\n",
    "heat = {0:0,'Floor':1,'GasA':2,'GasW':3,'Grav':4,'OthW':5,'Wall':6}\n",
    "yesno = {0:0, 'N':1,'Y':2}\n",
    "elect = {0:0,'SBrkr':1,'FuseA':2,'FuseF':3,'FuseP':4,'Mix':5}\n",
    "func = {0:0,'Typ':1,'Min1':2,'Min2':3,'Mod':4,'Maj1':5,'Maj2':6,'Sev':7,'Sal':8}\n",
    "gt = {0:0,'2Types':1,'Attchd':2,'Basment':3,'BuiltIn':4,'CarPort':5,'Detchd':6}\n",
    "gfin = {0:0,'Fin':1,'RFn':2,'Unf':3}\n",
    "pd = {0:0,'Y':1,'P':2,'N':3}\n",
    "fence = {0:0,'GdPrv':1,'MnPrv':2,'GdWo':3,'MnWw':4}\n",
    "misc = {0:0,'Elev':1,'Gar2':2,'Othr':3,'Shed':4,'TenC':5}\n",
    "stype = {0:0,'WD':1,'CWD':2,'VWD':3,'New':4,'COD':4,'Con':5,'ConLw':6,'ConLI':7,'ConLD':8,'Oth':9}\n",
    "scond = {0:0,'Normal':1,'Abnorml':2,'AdjLand':3,'Alloca':4,'Family':5,'Partial':6}\n",
    "# traversing through dataframe\n",
    "# Gender column and writing\n",
    "# values where key matches\n",
    "data=data.fillna(0)\n",
    "data.MSZoning = [zone[item] for item in data.MSZoning]\n",
    "data.Alley = [alley[item] for item in data.Alley]\n",
    "data.LotShape = [lot[item] for item in data.LotShape]\n",
    "data.LandContour = [contour[item] for item in data.LandContour]\n",
    "data.Utilities = [utils[item] for item in data.Utilities]\n",
    "data.LotConfig = [lotconfig[item] for item in data.LotConfig]\n",
    "data.LandSlope = [landslop[item] for item in data.LandSlope]\n",
    "data.Neighborhood = [nhd[item] for item in data.Neighborhood]\n",
    "data.Condition1 = [cond[item] for item in data.Condition1]\n",
    "data.Condition2 = [cond[item] for item in data.Condition2]\n",
    "data.BldgType = [btype[item] for item in data.BldgType]\n",
    "data.HouseStyle = [hstyle[item] for item in data.HouseStyle]\n",
    "data.RoofStyle = [roof[item] for item in data.RoofStyle]\n",
    "data.RoofMatl = [roofmatl[item] for item in data.RoofMatl]\n",
    "data.Street = [street[item] for item in data.Street]\n",
    "data.Exterior1st = [ext[item] for item in data.Exterior1st]\n",
    "data.Exterior2nd = [ext[item] for item in data.Exterior2nd]\n",
    "data.MasVnrType = [mvt[item] for item in data.MasVnrType]\n",
    "data.ExterQual = [eq[item] for item in data.ExterQual]\n",
    "data.ExterCond = [eq[item] for item in data.ExterCond]\n",
    "data.Foundation = [found[item] for item in data.Foundation]\n",
    "data.BsmtQual = [eq[item] for item in data.BsmtQual]\n",
    "data.BsmtCond = [eq[item] for item in data.BsmtCond]\n",
    "data.BsmtExposure = [bex[item] for item in data.BsmtExposure]\n",
    "data.BsmtFinType1 = [bsmt_type[item] for item in data.BsmtFinType1]\n",
    "data.BsmtFinType2 = [bsmt_type[item] for item in data.BsmtFinType2]\n",
    "data.Heating = [heat[item] for item in data.Heating]\n",
    "data.HeatingQC = [eq[item] for item in data.HeatingQC]\n",
    "data.CentralAir = [yesno[item] for item in data.CentralAir]\n",
    "data.Electrical = [elect[item] for item in data.Electrical]\n",
    "data.KitchenQual = [eq[item] for item in data.KitchenQual]\n",
    "data.Functional = [func[item] for item in data.Functional]\n",
    "data.FireplaceQu = [eq[item] for item in data.FireplaceQu]\n",
    "data.GarageType = [gt[item] for item in data.GarageType]\n",
    "data.GarageFinish = [gfin[item] for item in data.GarageFinish]\n",
    "data.GarageQual = [eq[item] for item in data.GarageQual]\n",
    "data.GarageCond = [eq[item] for item in data.GarageCond]\n",
    "data.PavedDrive = [pd[item] for item in data.PavedDrive]\n",
    "data.PoolQC = [eq[item] for item in data.PoolQC]\n",
    "data.Fence = [fence[item] for item in data.Fence]\n",
    "data.MiscFeature = [misc[item] for item in data.MiscFeature]\n",
    "data.SaleType = [stype[item] for item in data.SaleType]\n",
    "data.SaleCondition = [scond[item] for item in data.SaleCondition]\n",
    "\n",
    "data.to_csv('clean2.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/ash/clean.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5bd5e0489e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ash/clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ash/clean2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/home/ash/clean.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/home/ash/drop/clean.csv')\n",
    "data2 = pd.read_csv('/home/ash/clean2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = data.drop(columns=['Id','SalePrice'])\n",
    "train_y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = data2.drop(columns=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(data['MSSubClass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_X, val_X, train_y, val_y = train_test_split(train_X, train_y, random_state=1)\\n# Specify Model\\niowa_model = DecisionTreeRegressor(random_state=1)\\n# Fit Model\\niowa_model.fit(train_X, train_y)\\n\\n# Make validation predictions and calculate mean absolute error\\nval_predictions = iowa_model.predict(val_X)\\nval_mae = mean_absolute_error(val_predictions, val_y)\\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\\n\\n# Using best value for max_leaf_nodes\\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\\niowa_model.fit(train_X, train_y)\\nval_predictions = iowa_model.predict(val_X)\\nval_mae = mean_absolute_error(val_predictions, val_y)\\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\\n\\n# Define the model. Set random_state to 1\\nrf_model = RandomForestRegressor(random_state=1)\\nrf_model.fit(train_X, train_y)\\nrf_val_predictions = rf_model.predict(val_X)\\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\\n\\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, random_state=1)\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Using best value for max_leaf_nodes\n",
    "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "output = pd.DataFrame({'Id': data2.Id,\n",
    "                       'SalePrice': rf_val_predictions})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
